{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiastornquist/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lstm_vae import create_lstm_vae, inference\n",
    "from train import get_text_data\n",
    "import keras\n",
    "import sys, time\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(params):\n",
    "    \n",
    "    num_samples = int(params['num_samples'])\n",
    "    data_path = \"data/\" + params['dataset']\n",
    "    dataname = params['dataset'].split('.')[0]\n",
    "    \n",
    "    batch_size = int(params['batch_size'])\n",
    "    latent_dim = int(params['latent_dim'])\n",
    "    intermediate_dim = int(params['intermediate_dim'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    train = int(params['train'])\n",
    "    save = int(params['save'])\n",
    "    load = int(params['load'])\n",
    "    \n",
    "    print_default = int(params['print_default'])\n",
    "    \n",
    "   \n",
    "    timesteps_max, enc_tokens, characters, char2id, id2char, x, x_decoder = get_text_data(num_samples=num_samples,\n",
    "                                                                                          data_path=data_path)\n",
    "\n",
    "    \n",
    "    input_dim = x.shape[-1]\n",
    "    timesteps = x.shape[-2]\n",
    "\n",
    "        \n",
    "    if load:\n",
    "        print(\"Loading model ... \")\n",
    "        \n",
    "        #vae = keras.models.load_model(\"models/vae_{}_{}.h5\".format(dataname, num_samples))\n",
    "        enc = keras.models.load_model(\"models/encoder_{}_{}.h5\".format(dataname, num_samples))\n",
    "        gen = keras.models.load_model(\"models/generator_{}_{}.h5\".format(dataname, num_samples))\n",
    "        stepper = keras.models.load_model(\"models/stepper_{}_{}.h5\".format(dataname, num_samples))\n",
    "    \n",
    "    if train:\n",
    "        print(\"Training model...\")\n",
    "        \n",
    "        vae, enc, gen, stepper = create_lstm_vae(input_dim,\n",
    "                                             batch_size=batch_size,\n",
    "                                             intermediate_dim=intermediate_dim,\n",
    "                                             latent_dim=latent_dim)\n",
    "        \n",
    "        csv_logger = CSVLogger('training_vae.log', separator=',', append=False)\n",
    "        vae.fit([x, x_decoder], x, epochs=epochs, verbose=1, callbacks=[csv_logger])\n",
    "        \n",
    "        if save:\n",
    "            print(\"Saving model ... \")\n",
    "            \n",
    "            vae.save(\"models/vae_{}_{}.h5\".format(dataname, num_samples))\n",
    "            enc.save(\"models/encoder_{}_{}.h5\".format(dataname, num_samples))\n",
    "            gen.save(\"models/generator_{}_{}.h5\".format(dataname, num_samples))\n",
    "            stepper.save(\"models/stepper_{}_{}.h5\".format(dataname, num_samples))\n",
    "\n",
    "    def decode(s, start_char = \"\\t\"):\n",
    "        return inference.decode_sequence(s, gen, stepper, input_dim, char2id, id2char, timesteps_max, start_char = start_char)\n",
    "\n",
    "    def continue_seq(x_start, states_value, h0 = False, sampling = False):\n",
    "        return inference.continue_sequence(x_start, states_value, h0, sampling, gen, stepper, input_dim, char2id, id2char, timesteps_max)\n",
    "    \n",
    "    if print_default:\n",
    "\n",
    "        for _ in range(6):\n",
    "            id_from = np.random.randint(0, x.shape[0] - 1)\n",
    "            id_sentence = np.random.randint(0, x.shape[0] - 1)\n",
    "\n",
    "            n_words = np.sum(x[id_sentence])\n",
    "            n_kept = np.random.randint(n_words//2, n_words-1)\n",
    "\n",
    "            new_x = np.zeros((x[id_sentence].shape))\n",
    "            new_x[:n_kept,:] = x[id_sentence,:n_kept,:]\n",
    "\n",
    "            m_new, std_new = enc.predict([[x[id_from]]])\n",
    "            h_new = np.random.normal(size=(latent_dim,))\n",
    "            states_new = m_new + std_new * h_new\n",
    "\n",
    "            print(\"==  \\t\", \" \".join([id2char[j] for j in np.argmax(new_x[:n_kept], axis=1)]), \" ... \\t\\t ==\")\n",
    "\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new))\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, h0 = True))\n",
    "\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, sampling = True))\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, h0 = True, sampling = True))\n",
    "\n",
    "\n",
    "            print(\"==  \\t\", \" \".join([id2char[j] for j in np.argmax(x[id_sentence], axis=1)]), \"==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes file to local data filder\n",
    "print(webtext.fileids())\n",
    "raw_text = webtext.raw(webtext.fileids()[5])\n",
    "listan = [sentence.replace('\\t','').replace('*','').replace('\\n','').strip() for sentence in re.split(\"[.!?]+\", raw_text) if len(sentence.split())>3]\n",
    "with open('data/wine.txt','w') as f:\n",
    "    for sentence in listan:\n",
    "        f.write(sentence+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 1\n",
    "params['latent_dim'] = 191\n",
    "params['intermediate_dim'] = 353\n",
    "params['epochs'] = 60\n",
    "params['verbose'] = 1\n",
    "params['num_samples'] = len(listan)\n",
    "params['data_type'] = \"text\"\n",
    "params['dataset'] = webtext.fileids()[5] #'wine.txt'\n",
    "params['train'] = 1\n",
    "params['save'] = 1\n",
    "params['load'] = 0\n",
    "params['print_default'] = 1\n",
    "\n",
    "main(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads the wine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import webtext\n",
    "print(webtext.fileids())\n",
    "raw_text = webtext.raw(webtext.fileids()[5])\n",
    "listan = [sentence.replace('\\t','').replace('*','').replace('\\n','').strip() for sentence in re.split(\"[.!?]+\", raw_text) if len(sentence.split())>3]\n",
    "params = {}\n",
    "params['batch_size'] = 1\n",
    "params['latent_dim'] = 191\n",
    "params['intermediate_dim'] = 353\n",
    "params['epochs'] = 40\n",
    "params['verbose'] = 1\n",
    "params['num_samples'] = len(listan)\n",
    "params['data_type'] = \"text\"\n",
    "params['dataset'] = webtext.fileids()[5] # 'wine.txt'\n",
    "params['separator'] = \"\\n\"\n",
    "params['train'] = 0\n",
    "params['save'] = 0\n",
    "params['load'] = 1\n",
    "params['print_default'] = 1\n",
    "\n",
    "main(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
