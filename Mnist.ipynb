{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "timesteps_max, enc_tokens, x, x_decoder = get_mnist_data(num_samples=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 29, 28) Creating model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 353)          539384      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 191)          67614       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 191)          67614       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 191)          0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 353)          67776       lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 353),  539384      input_7[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 28)     9912        lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,291,684\n",
      "Trainable params: 1,291,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training model...\n",
      "Epoch 1/40\n",
      "5000/5000 [==============================] - 33s 7ms/step - loss: 9.7485 - xent_loss: 9.7411 - kl_loss: 0.0074\n",
      "Epoch 2/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 9.0315 - xent_loss: 9.0240 - kl_loss: 0.0075\n",
      "Epoch 3/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.8768 - xent_loss: 8.8702 - kl_loss: 0.0066\n",
      "Epoch 4/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.7723 - xent_loss: 8.7667 - kl_loss: 0.0056\n",
      "Epoch 5/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.6997 - xent_loss: 8.6945 - kl_loss: 0.0052\n",
      "Epoch 6/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.6379 - xent_loss: 8.6330 - kl_loss: 0.0049\n",
      "Epoch 7/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.5925 - xent_loss: 8.5879 - kl_loss: 0.0046\n",
      "Epoch 8/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.5518 - xent_loss: 8.5471 - kl_loss: 0.0047\n",
      "Epoch 9/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.5247 - xent_loss: 8.5201 - kl_loss: 0.0046\n",
      "Epoch 10/40\n",
      "5000/5000 [==============================] - 31s 6ms/step - loss: 8.4955 - xent_loss: 8.4909 - kl_loss: 0.0046\n",
      "Epoch 11/40\n",
      "5000/5000 [==============================] - 31s 6ms/step - loss: 8.4751 - xent_loss: 8.4706 - kl_loss: 0.0045\n",
      "Epoch 12/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.4525 - xent_loss: 8.4480 - kl_loss: 0.0045\n",
      "Epoch 13/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.4325 - xent_loss: 8.4282 - kl_loss: 0.0043\n",
      "Epoch 14/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.4138 - xent_loss: 8.4096 - kl_loss: 0.0042\n",
      "Epoch 15/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3950 - xent_loss: 8.3910 - kl_loss: 0.0041\n",
      "Epoch 16/40\n",
      "5000/5000 [==============================] - 32s 6ms/step - loss: 8.3791 - xent_loss: 8.3752 - kl_loss: 0.0039\n",
      "Epoch 17/40\n",
      "5000/5000 [==============================] - 32s 6ms/step - loss: 8.3719 - xent_loss: 8.3677 - kl_loss: 0.0041\n",
      "Epoch 18/40\n",
      "5000/5000 [==============================] - 32s 6ms/step - loss: 8.3603 - xent_loss: 8.3563 - kl_loss: 0.0040\n",
      "Epoch 19/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.3483 - xent_loss: 8.3444 - kl_loss: 0.0039\n",
      "Epoch 20/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3442 - xent_loss: 8.3402 - kl_loss: 0.0040\n",
      "Epoch 21/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3259 - xent_loss: 8.3220 - kl_loss: 0.0038\n",
      "Epoch 22/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3183 - xent_loss: 8.3146 - kl_loss: 0.0037\n",
      "Epoch 23/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3162 - xent_loss: 8.3124 - kl_loss: 0.0038\n",
      "Epoch 24/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.3061 - xent_loss: 8.3024 - kl_loss: 0.0038\n",
      "Epoch 25/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2974 - xent_loss: 8.2936 - kl_loss: 0.0038\n",
      "Epoch 26/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2914 - xent_loss: 8.2877 - kl_loss: 0.0037\n",
      "Epoch 27/40\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 8.2874 - xent_loss: 8.2837 - kl_loss: 0.0037\n",
      "Epoch 28/40\n",
      "5000/5000 [==============================] - 31s 6ms/step - loss: 8.2802 - xent_loss: 8.2765 - kl_loss: 0.0037\n",
      "Epoch 29/40\n",
      "5000/5000 [==============================] - 31s 6ms/step - loss: 8.2744 - xent_loss: 8.2708 - kl_loss: 0.0036\n",
      "Epoch 30/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2664 - xent_loss: 8.2628 - kl_loss: 0.0035\n",
      "Epoch 31/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2697 - xent_loss: 8.2660 - kl_loss: 0.0036\n",
      "Epoch 32/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2591 - xent_loss: 8.2554 - kl_loss: 0.0037\n",
      "Epoch 33/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2544 - xent_loss: 8.2509 - kl_loss: 0.0035\n",
      "Epoch 34/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2491 - xent_loss: 8.2457 - kl_loss: 0.0034\n",
      "Epoch 35/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2483 - xent_loss: 8.2448 - kl_loss: 0.0035\n",
      "Epoch 36/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2406 - xent_loss: 8.2372 - kl_loss: 0.0034\n",
      "Epoch 37/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2353 - xent_loss: 8.2319 - kl_loss: 0.0034\n",
      "Epoch 38/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2338 - xent_loss: 8.2304 - kl_loss: 0.0034\n",
      "Epoch 39/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2302 - xent_loss: 8.2268 - kl_loss: 0.0033\n",
      "Epoch 40/40\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 8.2245 - xent_loss: 8.2211 - kl_loss: 0.0033\n",
      "Saving model ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiastornquist/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'dense_7/BiasAdd:0' shape=(?, 353) dtype=float32>, <tf.Tensor 'dense_7/BiasAdd:0' shape=(?, 353) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/Users/mathiastornquist/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'dense_7_1/BiasAdd:0' shape=(?, 353) dtype=float32>, <tf.Tensor 'dense_7_1/BiasAdd:0' shape=(?, 353) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "/Users/mathiastornquist/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'input_9:0' shape=(?, 353) dtype=float32>, <tf.Tensor 'input_10:0' shape=(?, 353) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted, predicting...\n",
      "== from \t ==\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e4570af2215a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"== from \\t ==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_from\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lstm_vae import create_lstm_vae, inference\n",
    "from train import get_text_data\n",
    "import keras\n",
    "import sys, time\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from tensorflow import set_random_seedPractical Bayesian optimization of machine learning algorithms\n",
    "set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "def get_mnist_data(num_samples=1000):\n",
    "            \n",
    "    # load data\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    n_inputs, height, max_length = X_train.shape\n",
    "    encoder_input_data = np.zeros((n_inputs, max_length + 1, height), dtype=\"float32\")\n",
    "    decoder_input_data = np.zeros((n_inputs, max_length + 1, height), dtype=\"float32\")\n",
    "    encoder_input_data[:,:max_length,:] = np.swapaxes(X_train, 1, 2).copy()/255\n",
    "    decoder_input_data[:,1:,:] = np.swapaxes(X_train, 1, 2).copy()/255\n",
    "\n",
    "    return max_length + 1, height, encoder_input_data[:num_samples,:,:], decoder_input_data[:num_samples,:,:]\n",
    "\n",
    "num_samples = 5000\n",
    "timesteps_max, enc_tokens, x, x_decoder = get_mnist_data(num_samples=num_samples)\n",
    "\n",
    "print(x.shape, \"Creating model...\")\n",
    "\n",
    "input_dim = x.shape[-1]\n",
    "timesteps = x.shape[-2]\n",
    "batch_size = 1\n",
    "latent_dim = 191\n",
    "intermediate_dim = 353\n",
    "epochs = 40\n",
    "\n",
    "vae, enc, gen, stPractical Bayesian optimization of machine learning algorithmsepper = create_lstm_vae(input_dim,\n",
    "                                         batch_size=batch_size,\n",
    "                                         intermediate_dim=intermediate_dim,\n",
    "                                         latent_dim=latent_dim)\n",
    "print(\"Training model...\")\n",
    "\n",
    "vae.fit([x, x_decoder], x, epochs=epochs, verbose=1)\n",
    "\n",
    "print(\"Saving model ... \")\n",
    "\n",
    "vae.save(\"models/vae_mnist_\"+str(num_samples)+\"_epoch_\"+str(epochs)+\".h5\")\n",
    "enc.save(\"models/encoder_mnist_\"+str(num_samples)+\"_epoch_\"+str(epochs)+\".h5\")\n",
    "gen.save(\"models/generator_mnist_\"+str(num_samples)+\"_epoch_\"+str(epochs)+\".h5\")\n",
    "stepper.save(\"models/stepper_mnist_\"+str(num_samples)+\"_epoch_\"+str(epochs)+\".h5\")\n",
    "\n",
    "print(\"Fitted, predicting...\")\n",
    "\n",
    "\n",
    "def decode(s):\n",
    "    return inference.decode_sequence(s, gen, stepper, input_dim, timesteps_max)\n",
    "\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    id_from = np.random.randint(0, x.shape[0] - 1)\n",
    "    id_to = np.random.randint(0, x.shape[0] - 1)\n",
    "\n",
    "    m_from, std_from = enc.predict([[x[id_from]]])\n",
    "    m_to, std_to = enc.predict([[x[id_to]]])\n",
    "\n",
    "    seq_from = np.random.normal(size=(latent_dim,))\n",
    "    seq_from = m_from + std_from * seq_from\n",
    "\n",
    "    seq_to = np.random.normal(size=(latent_dim,))\n",
    "    seq_to = m_to + std_to * seq_to\n",
    "\n",
    "    print(\"== from \\t ==\")\n",
    "    plt.imshow(x[id_from].T, cmap='Greys',  interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "    for v in np.linspace(0, 1, 7):\n",
    "        print(\"%.2f\\t\" % (1 - v))\n",
    "        plt.imshow(decode(v * seq_to + (1 - v) * seq_from).T, cmap='Greys',  interpolation='nearest')\n",
    "        plt.show()\n",
    "\n",
    "    print(\"== from \\t ==\")\n",
    "    plt.imshow(x[id_to].T, cmap='Greys',  interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(params):\n",
    "    \n",
    "    num_samples = int(params['num_samples'])\n",
    "    data_path = \"data/\" + params['dataset']\n",
    "    dataname = params['dataset'].split('.')[0]\n",
    "    \n",
    "    batch_size = int(params['batch_size'])\n",
    "    latent_dim = int(params['latent_dim'])\n",
    "    intermediate_dim = int(params['intermediate_dim'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    train = int(params['train'])\n",
    "    save = int(params['save'])\n",
    "    load = int(params['load'])\n",
    "    \n",
    "    print_default = int(params['print_default'])\n",
    "    \n",
    "   \n",
    "    timesteps_max, enc_tokens, characters, char2id, id2char, x, x_decoder = get_text_data(num_samples=num_samples,\n",
    "                                                                                          data_path=data_path)\n",
    "\n",
    "    \n",
    "    input_dim = x.shape[-1]\n",
    "    timesteps = x.shape[-2]\n",
    "\n",
    "        \n",
    "    if load:\n",
    "        print(\"Loading model ... \")\n",
    "        \n",
    "        #vae = keras.models.load_model(\"models/vae_{}_{}.h5\".format(dataname, num_samples))\n",
    "        enc = keras.models.load_model(\"models/encoder_{}_{}.h5\".format(dataname, num_samples))\n",
    "        gen = keras.models.load_model(\"models/generator_{}_{}.h5\".format(dataname, num_samples))\n",
    "        stepper = keras.models.load_model(\"models/stepper_{}_{}.h5\".format(dataname, num_samples))\n",
    "    \n",
    "    if train:\n",
    "        print(\"Training model...\")\n",
    "        \n",
    "        vae, enc, gen, stepper = create_lstm_vae(input_dim,\n",
    "                                             batch_size=batch_size,\n",
    "                                             intermediate_dim=intermediate_dim,\n",
    "                                             latent_dim=latent_dim)\n",
    "        \n",
    "        csv_logger = CSVLogger('training_vae.log', separator=',', append=False)\n",
    "        vae.fit([x, x_decoder], x, epochs=epochs, verbose=1, callbacks=[csv_logger])\n",
    "        \n",
    "        if save:\n",
    "            print(\"Saving model ... \")\n",
    "            \n",
    "            vae.save(\"models/vae_{}_{}.h5\".format(dataname, num_samples))\n",
    "            enc.save(\"models/encoder_{}_{}.h5\".format(dataname, num_samples))\n",
    "            gen.save(\"models/generator_{}_{}.h5\".format(dataname, num_samples))\n",
    "            stepper.save(\"models/stepper_{}_{}.h5\".format(dataname, num_samples))\n",
    "\n",
    "    def decode(s, start_char = \"\\t\"):\n",
    "        return inference.decode_sequence(s, gen, stepper, input_dim, char2id, id2char, timesteps_max, start_char = start_char)\n",
    "\n",
    "    def continue_seq(x_start, states_value, h0 = False, sampling = False):\n",
    "        return inference.continue_sequence(x_start, states_value, h0, sampling, gen, stepper, input_dim, char2id, id2char, timesteps_max)\n",
    "    \n",
    "    if print_default:\n",
    "\n",
    "        for _ in range(6):\n",
    "            id_from = np.random.randint(0, x.shape[0] - 1)\n",
    "            id_sentence = np.random.randint(0, x.shape[0] - 1)\n",
    "\n",
    "            n_words = np.sum(x[id_sentence])\n",
    "            n_kept = np.random.randint(n_words//2, n_words-1)\n",
    "\n",
    "            new_x = np.zeros((x[id_sentence].shape))\n",
    "            new_x[:n_kept,:] = x[id_sentence,:n_kept,:]\n",
    "\n",
    "            m_new, std_new = enc.predict([[x[id_from]]])\n",
    "            h_new = np.random.normal(size=(latent_dim,))\n",
    "            states_new = m_new + std_new * h_new\n",
    "\n",
    "            print(\"==  \\t\", \" \".join([id2char[j] for j in np.argmax(new_x[:n_kept], axis=1)]), \" ... \\t\\t ==\")\n",
    "\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new))\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, h0 = True))\n",
    "\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, sampling = True))\n",
    "            print(\"\\t...\\t\", continue_seq(new_x, states_new, h0 = True, sampling = True))\n",
    "\n",
    "\n",
    "            print(\"==  \\t\", \" \".join([id2char[j] for j in np.argmax(x[id_sentence], axis=1)]), \"==\")\n",
    "            \n",
    "            \n",
    "raw_text = webtext.raw(webtext.fileids()[5])\n",
    "listan = [sentence.replace('\\t','').replace('*','').replace('\\n','').strip() for sentence in re.split(\"[.!?]+\", raw_text) if len(sentence.split())>3]\n",
    "\n",
    "\n",
    "params = {}\n",
    "params['batch_size'] = 1\n",
    "params['latent_dim'] = 191\n",
    "params['intermediate_dim'] = 353\n",
    "params['epochs'] = 60\n",
    "params['verbose'] = 1\n",
    "params['num_samples'] = len(listan)\n",
    "params['data_type'] = \"text\"\n",
    "params['dataset'] = webtext.fileids()[5] #'wine.txt'\n",
    "params['train'] = 1\n",
    "params['save'] = 1\n",
    "params['load'] = 0\n",
    "params['print_default'] = 1\n",
    "\n",
    "main(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loads the wine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiastornquist/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "enc = keras.models.load_model(\"models/encoder_mnist_600000_samples_epochs_60.h5\")\n",
    "gen = keras.models.load_model(\"models/generator_mnist_600000_samples_epochs_60.h5\")\n",
    "stepper = keras.models.load_model(\"models/stepper_mnist_600000_samples_epochs_60.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== from \t ==\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00\t\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'char2id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-75400ae04e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.2f\\t\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_to\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-75400ae04e42>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(s, start_char)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'char2id' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def decode(s, start_char = \"\\t\"):\n",
    "        return inference.decode_sequence(s, gen, stepper, input_dim, timesteps_max, char2id, id2char, start_char = start_char, data_type = data_type)\n",
    "\n",
    "\n",
    "print(\"== from \\t ==\")\n",
    "plt.imshow(x[id_from].T, cmap='Greys',  interpolation='nearest')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "for v in np.linspace(0, 1, 7):\n",
    "    print(\"%.2f\\t\" % (1 - v))\n",
    "    plt.imshow(decode(v * seq_to + (1 - v) * seq_from).T, cmap='Greys',  interpolation='nearest')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "print(\"== to \\t ==\")\n",
    "plt.imshow(x[id_to].T, cmap='Greys',  interpolation='nearest')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
